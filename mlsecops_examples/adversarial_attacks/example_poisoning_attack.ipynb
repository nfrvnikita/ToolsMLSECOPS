{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from art.attacks.poisoning import PoisoningAttack\n",
    "from art.defences.detector import Me\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define the model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 2. Load the dataset\n",
    "def load_mnist_data():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "    testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "    return trainloader, testloader\n",
    "\n",
    "# 3. Train the model\n",
    "def train_model(model, trainloader, criterion, optimizer, epochs=2):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}\")\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "# 4. Convert PyTorch model to ART classifier\n",
    "def get_art_classifier(model):\n",
    "    return PyTorchClassifier(\n",
    "        model=model,\n",
    "        loss=nn.CrossEntropyLoss(),\n",
    "        optimizer=optim.SGD(model.parameters(), lr=0.01),\n",
    "        input_shape=(1, 28, 28),\n",
    "        nb_classes=10\n",
    "    )\n",
    "\n",
    "# 5. Implement Poisoning Attack\n",
    "def apply_poisoning_attack(art_classifier, trainloader):\n",
    "    # Poisoning attack parameters\n",
    "    poison_fraction = 0.1  # Fraction of poisoned data\n",
    "    poison_target = 1  # Target class for the attack\n",
    "    \n",
    "    poison_attack = PoisoningAttack(\n",
    "        classifier=art_classifier,\n",
    "        poison_fraction=poison_fraction,\n",
    "        target_class=poison_target\n",
    "    )\n",
    "    \n",
    "    # Poison the training data\n",
    "    poisoned_data, poisoned_labels = poison_attack.generate_poisoned_data(trainloader.dataset.data, trainloader.dataset.targets)\n",
    "    \n",
    "    # Create a poisoned dataloader\n",
    "    poisoned_dataset = torch.utils.data.TensorDataset(poisoned_data, poisoned_labels)\n",
    "    poisoned_loader = torch.utils.data.DataLoader(poisoned_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    return poisoned_loader\n",
    "\n",
    "# 6. Evaluate the model\n",
    "def evaluate_model(model, testloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the network on the test images: {100 * correct // total}%')\n",
    "\n",
    "# 7. Visualize some samples\n",
    "def visualize_samples(data_loader, title):\n",
    "    images, labels = next(iter(data_loader))\n",
    "    images = images.numpy()\n",
    "    labels = labels.numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for i in range(5):\n",
    "        axes[i].imshow(images[i].squeeze(), cmap='gray')\n",
    "        axes[i].set_title(f'Label: {labels[i]}')\n",
    "        axes[i].axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# 8. Main function\n",
    "def main():\n",
    "    # Load data\n",
    "    trainloader, testloader = load_mnist_data()\n",
    "    \n",
    "    # Initialize and train model\n",
    "    model = SimpleCNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    train_model(model, trainloader, criterion, optimizer, epochs=2)\n",
    "    \n",
    "    # Convert to ART classifier\n",
    "    art_classifier = get_art_classifier(model)\n",
    "    \n",
    "    # Evaluate on clean model\n",
    "    print(\"Evaluating clean model:\")\n",
    "    evaluate_model(model, testloader)\n",
    "    visualize_samples(testloader, 'Clean Test Samples')\n",
    "    \n",
    "    # Apply poisoning attack\n",
    "    poisoned_loader = apply_poisoning_attack(art_classifier, trainloader)\n",
    "    \n",
    "    # Re-train model on poisoned data\n",
    "    print(\"Re-training model on poisoned data:\")\n",
    "    train_model(model, poisoned_loader, criterion, optimizer, epochs=2)\n",
    "    \n",
    "    # Evaluate on poisoned model\n",
    "    print(\"Evaluating poisoned model:\")\n",
    "    evaluate_model(model, testloader)\n",
    "    visualize_samples(testloader, 'Poisoned Test Samples')\n",
    "\n",
    "    # Apply defense\n",
    "    print(\"Applying Median Smoothing defense:\")\n",
    "    defense = MedianSmoothing()\n",
    "    art_classifier = get_art_classifier(model)\n",
    "    art_classifier.defense = defense\n",
    "\n",
    "    # Re-train model on poisoned data with defense\n",
    "    print(\"Re-training model on poisoned data with defense:\")\n",
    "    train_model(model, poisoned_loader, criterion, optimizer, epochs=2)\n",
    "    \n",
    "    # Evaluate with defense\n",
    "    print(\"Evaluating model with defense:\")\n",
    "    evaluate_model(model, testloader)\n",
    "    visualize_samples(testloader, 'Defended Test Samples')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
